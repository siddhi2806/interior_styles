#!/usr/bin/env python3
"""
Quick AI Setup Verification Script for Room Styler
Fast tests without running the full AI pipeline
"""

import sys
import os
from pathlib import Path

def test_pytorch():
    """Test PyTorch installation and CUDA availability"""
    print("ğŸ” Testing PyTorch Installation...")
    
    try:
        import torch
        print(f"âœ… PyTorch version: {torch.__version__}")
        print(f"âœ… CUDA version: {torch.version.cuda}")
        print(f"âœ… CUDA available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"âœ… GPU count: {torch.cuda.device_count()}")
            print(f"âœ… Current device: {torch.cuda.get_device_name(0)}")
        else:
            print("â„¹ï¸  Running on CPU (GPU acceleration not available)")
        
        return True
    except ImportError as e:
        print(f"âŒ PyTorch import failed: {e}")
        return False

def test_ai_dependencies():
    """Test AI-related package imports"""
    print("\nğŸ” Testing AI Dependencies...")
    
    packages = {
        'transformers': 'Hugging Face Transformers',
        'diffusers': 'Diffusers for Stable Diffusion',
        'PIL': 'Pillow for image processing',
        'accelerate': 'Accelerate for model optimization'
    }
    
    success = True
    for package, description in packages.items():
        try:
            __import__(package)
            print(f"âœ… {description}")
        except ImportError as e:
            print(f"âŒ {description}: {e}")
            success = False
    
    return success

def test_model_cache():
    """Check if models are cached"""
    print("\nğŸ” Checking Model Cache...")
    
    cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
    
    if cache_dir.exists():
        cached_models = list(cache_dir.glob("models--*"))
        print(f"âœ… Found {len(cached_models)} cached models")
        
        # Look for specific models
        blip_model = any("vit-gpt2-image-captioning" in str(m) for m in cached_models)
        sd_model = any("stable-diffusion-2-1" in str(m) for m in cached_models)
        
        if blip_model:
            print("âœ… BLIP model cached")
        else:
            print("â„¹ï¸  BLIP model not cached (will download on first run)")
            
        if sd_model:
            print("âœ… Stable Diffusion model cached")
        else:
            print("â„¹ï¸  Stable Diffusion model not cached (will download on first run)")
        
        return len(cached_models) > 0
            
    else:
        print("â„¹ï¸  No Hugging Face cache found (models will download on first run)")
        return True  # This is not an error, just means first run

def test_script_exists():
    """Check if the room styler script exists and has correct structure"""
    print("\nğŸ” Testing Room Styler Script...")
    
    script_path = Path("src/python/room_styler.py")
    if not script_path.exists():
        print(f"âŒ Script not found: {script_path}")
        return False
    
    print(f"âœ… Script found: {script_path}")
    
    # Check for test images
    tmp_dir = Path("tmp")
    if not tmp_dir.exists():
        print("âŒ tmp/ directory not found")
        return False
    
    test_images = list(tmp_dir.glob("*.png"))
    if not test_images:
        print("âŒ No test images found in tmp/ directory")
        return False
    
    print(f"âœ… Found {len(test_images)} test images")
    
    # Check if we have previous AI output
    ai_outputs = [f for f in tmp_dir.glob("*ai*.png")]
    if ai_outputs:
        print(f"âœ… Found {len(ai_outputs)} AI-generated images (previous runs)")
    
    return True

def test_imports_work():
    """Test that we can import the AI models without errors"""
    print("\nğŸ” Testing Model Imports...")
    
    try:
        print("Loading transformers...")
        from transformers import pipeline
        print("âœ… Transformers loaded")
        
        print("Loading diffusers...")
        from diffusers import StableDiffusionImg2ImgPipeline
        print("âœ… Diffusers loaded")
        
        print("Loading PIL...")
        from PIL import Image
        print("âœ… PIL loaded")
        
        return True
    except Exception as e:
        print(f"âŒ Import error: {e}")
        return False

def main():
    """Run all tests"""
    print("ğŸ¤– Room Styler AI - Quick Setup Check")
    print("=" * 50)
    
    # Change to project directory
    os.chdir(Path(__file__).parent)
    
    tests = [
        ("PyTorch Installation", test_pytorch),
        ("AI Dependencies", test_ai_dependencies),
        ("Model Cache", test_model_cache),
        ("Script & Files", test_script_exists),
        ("Model Imports", test_imports_work)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"âŒ {test_name} failed with exception: {e}")
            results.append((test_name, False))
    
    # Summary
    print("\n" + "=" * 50)
    print("ğŸ“Š Test Results Summary:")
    
    all_passed = True
    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name}")
        if not success:
            all_passed = False
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸ‰ All tests passed! Your AI setup is ready!")
        print("ğŸš€ The AI pipeline is ready to use.")
        print("ğŸ’¡ Run the full test with: python test_ai_setup.py")
    else:
        print("âš ï¸  Some tests failed. Please check the errors above.")
        print("ğŸ“– Refer to AI_SETUP_GUIDE.md for troubleshooting.")
    
    # Additional info
    print("\nğŸ“‹ Next Steps:")
    print("   1. Run 'npm run dev' to start the web application")
    print("   2. Upload a room image and select a style")
    print("   3. The AI will generate a styled version")
    print("   4. First generation may take 5-15 minutes (model loading)")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    sys.exit(main())
